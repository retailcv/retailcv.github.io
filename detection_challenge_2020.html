---
layout: default
title: Detection Challenge 2020
---
<!-- Main -->
<article id="main">
    
<!-- One -->
    <section class="wrapper style3 container special">

                <!-- <header class="major"> -->
                    <!-- <h2 class="overview">Challenge Overview</h2> -->
                <!-- </header> -->
                <h2 id="challenge_overview_title">Product Detection in Densely Packed Scenes</h2><br>
                <h2>Challenge Overview</h2>

                <div id="line_wrapper"><div id="major_line"></div></div>

                <p>
                    The world of retail takes the detection scenario to unexplored territories with millions of possible facets and hundreds of heavily crowded objects per image. This challenge is based on the <a href="https://github.com/eg4000/SKU110K_CVPR19">SKU-110K dataset</a> collected from Traxâ€™s data of supermarket shelves and pushes the limits of detection systems.
                </p>

                <img src="/images/detection_challenge_2020/teaser.png" width=80%>
                <p>A typical image in our SKU-110K, showing densely packed objects</p>
    </section>

    <section class="wrapper style3 container special">

                <header class="major">
                    <h2 class="overview">Dataset</h2>
                </header>

                <div id="line_wrapper"><div id="major_line"></div></div>

                <p>
                    The SKU-110K dataset collects 11,762 densely packed shelf images from thousands of supermarkets around the world, including locations in the United States, Europe, and East Asia. The dataset can be downloaded from <a href="http://trax-geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz"> here</a> or <a href="https://drive.google.com/file/d/1iq93lCdhaPUN0fWbLieMtzfB1850pKwd">here</a> and is provided solely for academic and non-commercial purposes.
                </p>

                <center><img src="/images/detection_challenge_2020/benchmarks_comparison.jpg" width=80%><center>
                <p>Comparison of related benchmarks. #Img.: number of images. #Obj./img.: average items per image. #Cls.: number of object classes (more implies a harder detection problem due to greater appearance variations). #Cls./img.: average classes per image. dense: objects are typically densely packed. Idnt: images contain multiple identical objects or hard to separate object sub-regions. BB: bounding box labels are available.</p>

    </section>

    <section class="wrapper style3 container special">

                <header class="major">
                    <h2 class="overview">Challenge Info</h2>
                </header>

                <div id="line_wrapper"><div id="major_line"></div></div>

                <p>
                    This challenge includes a single track, where participants are invited to develop and train their methods using the data in the SKU-110K dataset and be tested on a yet to be released test set. Challenge winners will receive prizes and may be invited to give a presentation at the <a href="/">workshop</a>:
                </p>
                <img src="/images/prizes_BIG.png" style="max-width:50%; height:auto;">

                <h3>Procedure and Evaluation</h3>
                <p>All the data in the SKU-110K dataset may be used for training, including the validation and test sets. Methods will be evaluated on a new test set that will be released later on (see dates in the main workshop <a href="/">page</a>). The test set will be published without annotations. Detection results will be evaluated using the code in <a href="/data/densely_packed_eval_2020-02-06.zip">densely_packed_eval_2020-02-06.zip</a>.</p>
                <p> For questions about the challenge or to submit your results for evaluation please contact Ehud Barnea (ehudb at traxretail dot com).</p>

                <h3 style="color:red">Clarifications (posted at May 13)</h3>
                <p>Test-set images without annotations will be published by the 28th of May. To participate in the challenge please submit your results and preferred contact details to the email below by June 4 10:00 UTC+8. There is no need to register. The results file should have the same structure as the provided file "example_results.csv". Please use the train-set annotations and the provided code to make sure your results file is structured properly. </p>

                <p>
                    Results will be announced by email at June 6. <font style="color:red">Winners must provide a document presenting their method by June 13 to be eligible for the reward</font>. Other participants are encouraged to present their methods as well. Please post your documents in arXiv and send us a link. Received methods will be published in the challenge website. Authors may also be invited to present a talk at the workshop (the details of the virtual conference are still unclear but there will probably be a slot in the schedule that links to pre-recorded talks that we present in the website). 
                </p>

                <h3 style="color:red">Test data released (posted at May 27)</h3>
                <p>Test-set images without annotations can be found <a href="https://trax-geometry.s3.amazonaws.com/cvpr_challenge/cvpr2020_testset.zip">here</a>.
                Please review the clarifications above. All emails will be answered so you know they were not missed.
                </p>

                <h3>Questions and Submissions</h3>
                <p> For questions about the challenge or to submit your results for evaluation please contact Ehud Barnea (ehudb at traxretail dot com).</p>
    </section>


</article>
<br><div style="text-align: center; font-size: 20px;">Adapted from <a href="http://dynavis.github.io">dynavis.github.io</a></div><br>